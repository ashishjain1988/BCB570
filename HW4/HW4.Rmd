---
title: "BCB570 Assignment 4"
author: "Ashish Jain"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
    echo = TRUE,
    message = FALSE,
    warning = FALSE
)
library("tidyverse")
library("MASS")
library("ggplot2")
```

#Question 4:

##a) Bagging
Bootstrap aggregation is called as Bagging. Before explaining bagging first I would like to explain what bootstrap is. Bootstrap is random sampling with replacement which has been used to estimate the sample distribution. Now, bagging is a type of Ensembl method in which bootstrapping is carried out a number of times and the final result is being calculated by taking the average of the all the bootstrap samples. For example, if we have a training set D of size n, we can generate k new training set $D_j$ of size n, by sampling the original training set D uniformly and with replacement. These training sets can have duplicate observations as the sampling is carried out with replacement. From definition, each sampling is called as bootstrapping and the generation of k new training set is called as bagging. Finally, the generated k models generated are combined by taking the average (regression) or through voting (classification).

##b)

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
normalData<-rnorm(100, mean = 2.5, sd = sqrt(10))
baggedData<-matrix(nrow = 20,ncol = 10)
for(i in 1:20)
{
  baggedData[i,]<-sample(normalData,10,replace = TRUE)
}

sampleMean<-apply(baggedData,1,mean)
sampleVariance<-(apply(baggedData,1,var))
hist(sampleMean)
hist(sampleVariance)
samMean<-mean(sampleMean)
samVariance<-mean(sampleVariance)
```

The estimated value of the mean after bagging is `r samMean` and the variance is `r samVariance`.

#Question 5:

##a).

#WGCNA
In WGCNA, we first calculated the soft threshold for calculating the the power of the adjacency matrix. In this, I took the threshold at $R^2$ value. After that, we took the top quartile edge weight value as the threshold to filter the edges.

#GENIE3
In GENIE3, we first normalized the expression values as suggested in the GENIE3 paper. After that, we used 100 decision tress to predict the edges between the genes. After that, we took the top quartile value as the threshold to filter the edges. 

#ARACNE
In ARACNE, we took the we took the top quartile mutual information value as the threshold to filter the edges.

##b).

Below is the R code which has been used to run the different tools on the dataset and then filter the edges based on their respective scores. As, we mentioned we filtered edges based on top quartile value. 
Below is the code and the commands we have used to predict the GRNs using GENIE3 which is based on the random forest algorithm. In our case, we have used a total of 100 decision trees to predict the GRN.

```
#Code for GENIE3
source("/home/jain/Placenta_Geo_Dataset/GRN_Dataset/DREAM-5/GENIE3_R_C_wrapper/GENIE3_R_C_wrapper/GENIE3.R")
setwd("/home/jain/Placenta_Geo_Dataset/GRN_Dataset/DREAM-5/GENIE3_R_C_wrapper/GENIE3_R_C_wrapper/")
filePath<-"/home/jain/BCB570/Size_10/Size_10/DREAM4_training_data/insilico_size10_5/"
expr.matrix <- read.expr.matrix(paste0(filePath,"concatenateddata1.tsv"), form="rows.are.samples")

scaleData<-t(apply(expr.matrix,1,function(x){return((x-mean(x))/sd(x))}))
#TF<-read.table("/home/jain/Placenta_Geo_Dataset/GRN_Dataset/E7.5_Whole-Placenta/Mus_musculus_TF_EnsemblID.txt.geneName1.txt")
#intersect((row.names(expr.matrix)),as.character(TF[,1]))

weight.matrix1 <- GENIE3(scaleData,ncores = 8, K="all",ntrees = 100)
link.list <- get.link.list(weight.matrix1)
write.table(link.list,paste0(filePath,"GENIE3-allLinks.txt"),row.names = F)
#head(link.list)
truehist(link.list$weight)
png(filename=paste0(filePath,"GENIE3-densityPlot.png"), width = 1200, height = 800)
d <- density(link.list$weight) # returns the density data 
plot(d)
abline(v=quantile(link.list$weight,0.75), col = "red")
dev.off()
#link.list <- get.link.list(weight.matrix1, threshold=quantile(link.list$weight,0.75))
write.table(link.list[link.list$weight >= quantile(link.list$weight,0.75),],paste0(filePath,"GENIE3-filterLinks.txt"),row.names = F,col.names = F,sep = "\t")
```

WGCNA is weighted gene co-expression network analysis package in R which predicts the GRNs based on the co-expression analysis. In our case, we have used spearson correlation method to calculate the co-expression values. We have tried to make the network scale free but $R^2$ value for very high threshold is coming out to be only 0.4 which is not very good. The corresponding degree is also coming out to be very small. Due to these problems, we have taken power as 1 to calculate the adjacency matrix.

```
#Code for WGCNA
library(WGCNA)
library(igraph)
options(stringsAsFactors = FALSE);
filePath<-"/home/jain/BCB570/Size_10/Size_10/DREAM4_training_data/insilico_size10_5/"
datExpr <- read.table(paste0(filePath,"concatenateddata1.tsv"),header = T);
#write.table(t(as.matrix(datExpr)),paste0(filePath,"concatenateddata2.tsv"),row.names = T,sep = "\t")

#datExpr = as.data.frame(t(as.matrix(datExpr)))
powers = c(seq(from = 30, to=50, by=2))
# Call the network topology analysis function
sft = pickSoftThreshold(datExpr, powerVector = powers, verbose = 5)
# Plot the results:
sizeGrWindow(9, 5)
par(mfrow = c(1,2));
cex1 = 0.9;
png(filename=paste0(filePath,"WGCNA-densityPlot1.png"), width = 1200, height = 800)
plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
     xlab="Soft Threshold (power)",ylab="Scale Free Topology Model Fit,signed R^2",type="n",
     main = paste("Scale independence"));
text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
     labels=powers,cex=cex1,col="red");
abline(h=0.7,col="red")
dev.off()
png(filename=paste0(filePath,"WGCNA-densityPlot2.png"), width = 1200, height = 800)
plot(sft$fitIndices[,1], sft$fitIndices[,5],
     xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n",
     main = paste("Mean connectivity"))
text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col="red")
dev.off()

#softPower = 30
datAdj= adjacency(datExpr,
                  type = "unsigned",
                  power = 1,
                  corFnc = "cor", corOptions = "use = 'p', method = 'spearman'")

diag(datAdj) <- 0

threshold<-quantile(datAdj,0.75)
sig_values <- which(datAdj>threshold, arr.ind=TRUE) ##Find values greater than 0.5
Cor_Edges <- data.frame(rownames(datAdj)[sig_values[,1]],colnames(datAdj)[sig_values[,2]]) ##Build a table with Correlation values > 0.6.
#thres<-quantile(edges$weight,0.75)
ig <- graph.adjacency(datAdj, mode="directed", weighted=TRUE)
edges<-get.edgelist(ig)
weights<-edge_attr(ig,"weight")
edgesWithWT<-data.frame(cbind(edges,weights))
write.table(edgesWithWT[edgesWithWT$weights >= quantile(weights,0.75),],paste0(filePath,"WGCNA-filterLinks.txt"),row.names = F,col.names = F,sep = "\t")
```

ARACNE2 tool is based on the mutual information. It calculates and predicts the weights of the edges based on mutual information. In our study, we have used a java executable which takes gene expression files as an input. In this case, the gene expression file should contain gene as rows and samples as column. The results from this tool is not in a very good format, so we wrote a java code which give us the output as a list of edges with their weight. 

```
#Code for ARACNE2
java -jar aracne2\ \(1\).jar -i ./HW4_Yeast1-1/HW4_Yeast1-1/concatenateddata2.tsv -o ./HW4_Yeast1-1/HW4_Yeast1-1/ARCANE-adjMat.txt

#Code to convert the Results
import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.io.PrintWriter;

public class CreateEdgeListFromARACNE {

	public static void main(String[] args) throws IOException{
		for(int f=1;f<=5;f++)
		{
			String filePath = "/home/jain/BCB570/Size_10/Size_10/DREAM4_training_data/insilico_size10_"+f+"/";;
			BufferedReader br = new BufferedReader(new FileReader(filePath+"ARCANE-adjMat.txt"));
			String line = br.readLine();
			PrintWriter pw = new PrintWriter(filePath+"ARCANEedge.txt");
			while(line!=null)
			{
				if(!line.startsWith("<"))
				{
					String lineData[] = line.split("\t");
					String gene = lineData[0];
					for(int i=1;i<lineData.length-1;i=i+2)
					{
						pw.println(gene+"\t"+lineData[i]+"\t"+lineData[i+1]);
					}
				}
				line = br.readLine();
			}
			br.close();
			pw.close();
		}
	}
}
```

```
##R Code to Filter the size
filePath<-"/home/jain/BCB570/Size_10/Size_10/DREAM4_training_data/insilico_size10_5/"
edgesWithWT <-read.table(paste0(filePath,"ARCANEedge.txt"),header = F);
write.table(edgesWithWT[edgesWithWT$V3 >= quantile(edgesWithWT$V3,0.75),],paste0(filePath,"ARCANE-filterLinks.txt"),row.names = F,col.names = F,sep = "\t")
```

The gold standards given to us are directed but the results that we get from our tools are undirected. So, in order to make the Precision-Recall (PR) curves, we have made the gold standards undirected making both the directions for a particular edge as positive. After that, we have wrote a java code to calculate the PR values, using which a PR curve is made in R.

```
#PR Java Code
import java.io.BufferedReader;
import java.io.FileReader;
import java.io.IOException;
import java.io.PrintWriter;
import java.util.Arrays;
import java.util.Collections;
import java.util.Comparator;
import java.util.HashMap;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;

public class PrecisionRecallCurveValues {

	public static void main(String[] args) throws IOException{
		for(int f=1;f<=5;f++)
		{
			String filePath = "/home/jain/BCB570/Size_10/Size_10/DREAM4_training_data/insilico_size10_"+f+"/";
			BufferedReader br = new BufferedReader(new FileReader("/home/jain/BCB570/Size_10/Size_10/DREAM4_gold_standards/insilico_size10_"+f+"_goldstandard.tsv"));
			String line = br.readLine();
			Map<String, Integer> goldStandard = new HashMap<>();
			while(line!=null)
			{
				String lineData[] = line.split("\t");
				if(Integer.parseInt(lineData[2]) == 1)
				{
					goldStandard.put(lineData[0]+"-"+lineData[1], Integer.parseInt(lineData[2]));
					goldStandard.put(lineData[1]+"-"+lineData[0], Integer.parseInt(lineData[2]));
				}
				line = br.readLine();
			}
			br.close();
			List<String> toolList = Arrays.asList("WGCNA","GENIE3","ARCANE");
			for(String s:toolList)
			{
				String tool = s;
				Map<String, Float> predictData = new HashMap<>();
				br = new BufferedReader(new FileReader(filePath+tool+"-filterLinks.txt"));
				line = br.readLine();
				while(line!=null)
				{
					String lineData[] = line.split("\t");
					predictData.put(lineData[0]+"-"+lineData[1], Float.parseFloat(lineData[2]));
					line = br.readLine();
				}
				PrintWriter pw = new PrintWriter(filePath+tool+"-PrecisionRecallValues.txt");
				//Sort the map
				int postive = goldStandard.size();
				Map<String, Float> sortedPredictData = sortByComparatorValue(predictData);
				for(int i=1;i<=predictData.size();i++)
				{
					int j=0;
					float TP = 0;
					int FP = 0;
					float FN = 0;
					for(Entry<String, Float> entry : sortedPredictData.entrySet())
					{
						if(j<i)
						{
							if(goldStandard.containsKey(entry.getKey()))
							{
								TP = TP + 1;
							}else
							{
								FP = FP + 1;
							}
							j++;
						}else
						{
							break;
						}
					}
					FN = postive - TP;
					pw.println((TP/(TP+FP))+"\t"+(TP/(TP+FN)));
				}
				pw.close();
			}
		}
	}
	
	public static Map<String, Float> sortByComparatorValue(Map<String, Float> unsortMap) {
		 
		// Convert Map to List
		List<Map.Entry<String, Float>> list = 
			new LinkedList<Map.Entry<String, Float>>(unsortMap.entrySet());
 
		// Sort list with comparator, to compare the Map values
		Collections.sort(list, new Comparator<Map.Entry<String, Float>>() {
			public int compare(Map.Entry<String, Float> o1,
                                           Map.Entry<String, Float> o2) {
				return (o2.getValue()).compareTo(o1.getValue());
			}
		});
 
		// Convert sorted map back to a Map
		Map<String, Float> sortedMap = new LinkedHashMap<String, Float>();
		for (Iterator<Map.Entry<String, Float>> it = list.iterator(); it.hasNext();) {
			Map.Entry<String, Float> entry = it.next();
			sortedMap.put(entry.getKey(), entry.getValue());
		}
		return sortedMap;
	}
}
```


```{r}
##Code to plot the PR curve

filePath<-"/home/jain/BCB570/Size_10/Size_10/DREAM4_training_data/insilico_size10_5/"
WGCNA<-read.table(paste0(filePath,"WGCNA-PrecisionRecallValues.txt"),header = F)
GEN<-read.table(paste0(filePath,"GENIE3-PrecisionRecallValues.txt"),header = F)
ARCNE<-read.table(paste0(filePath,"ARCANE-PrecisionRecallValues.txt"),header = F)

#png(filename=paste0(filePath,"PR-Curve.png"), width = 1200, height = 800)
ggplot(data.frame(WGCNA,ARCNE,GEN),aes(x=WGCNA$V2,y=WGCNA$V1,color="WGCNA")) + ggtitle("PR Curve Network 5") + xlab("Recall") + ylab("Precision") + geom_line() + geom_line(aes(x=GEN$V2,y=GEN$V1,color="GENIE3")) + geom_line(aes(x=ARCNE$V2,y=ARCNE$V1,color="ARCNE"))
#dev.off()
```

The PR curves shows that in ARACNE2's performance is the best based on the insilico network results. GENIE3 is the second best and the results are pretty much close to that of the ARACNE2.


##c).

Based on the results from part b we used ARACNE2 for predicting the GRNs. As mentioned earlier, we have used top quartile value as the threshold for filtreing the edges. The results for both of the yeast networks are attached.
